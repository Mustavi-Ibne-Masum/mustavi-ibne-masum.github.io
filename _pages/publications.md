---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
---

<!-- <span style="color:black; font-family:Georgia;">Most recent publication updates can be found on my <a style ="color:#800080;" href=""><em>[Google Scholar]</em></a> profile.</span> -->

## 2023
<!-- --------- -->
<!-- 📃 -->
<!-- Paper 01 -->
<!-- ### Accepted ✔️-->
### Presented
---------
📃 <span style="color:#7D6E83;font-family:Trebuchet MS;">**Bengali News Abstractive Summarization: T5 Transformer and Hybrid Approach**</span><br>
<span style="color:black;font-family:Georgia">
	Khan Md Hasib, Md. Atiqur Rahman, <strong style="color:black">Mustavi Ibne Masum</strong>,  Friso De Boer, Sami Azam and Asif Kari, [DICTA 2023](https://www.dictaconference.org/)
</span>
<br>
<!-- [<a style="color:red;" href="#" onclick="$('#dicta2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>]
[[<span style ="color:red"><font size="3">PDF</font></span>](
	 paper link 
		)] [[<span style ="color:red"><font size="3">Code & Dataset</font></span>](
		 git link
		)] [[<span style ="color:red"><font size="3">Presentation</font></span>](
			git file link 
			)] [<a style="color:red;" href="#" onclick="$('#dicta2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] -->

<div id="dicta2023_bib" class="bib" style="display:none;">
	<pre>
	  @INPROCEEDINGS{<>,
	  author={},
	  booktitle={2023 International Conference on Digital Image Computing: Techniques and Applications (DICTA)}, 
	  title={Bengali News Abstractive Summarization: T5 Transformer and Hybrid Approach}, 
	  year={2023},
	  volume={},
	  number={},
	  pages={1-7},
	  doi={}}
	</pre>
</div>

<div id="dicta2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			In today's fast-paced world, everyone wants things to happen quickly. Thanks to the internet, news spreads super fast. But not all news is important. News summarization helps by giving a short version of each news story, so readers can easily figure out what type of news they want to read. There are two main types of summarization: Abstractive Text Summarization and Extractive Text Summarization. The process of abstractive text summarization is much more complex than that of extractive text summarization. This study proposes a model for generating extractive summaries, which are then utilized as input to generate abstractive summaries. The model uses the Bengali Text Summarization (BenSumm) model for extractive summarization and the Bangla Text-to-Text Transfer Transformer (BanlaT5) for abstractive summarization. The research also compares summarization acquired straight from the BanglaT5 model with summarization obtained via the proposed model. Abstractive summarization in the Bengali language has been accomplished using the Text-to-Text Transfer Transformer(T5) in this research. Although abstractive summarization of the Bengali language has been accomplished over the years using a variety of techniques, the field of using T5 in this field has only recently been discovered, and there is still a wide range of opportunities to be explored. The study has achieved promising results.
		</font>
	</p>
</div> 

📃 <span style="font-family:Trebuchet MS;color:#7D6E83">**Bengali Image Captioning Using Vision Encoder-Decoder Model**</span><br>
<span style="color:black;font-family:Georgia">
	Tajrian Islam Ishan, Abdullah Al Noman, Raisa Rokib, <strong style="color:black">Mustavi Ibne Masum</strong>, Sifat Ahmed, Faisal Muhammad Shah, [ICCIT 2023](https://iccit.org.bd/2023/)
</span>

<!-- [<a style="color:red;" href="#" onclick="$('#ecce2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>]( 
	 paper link
	)] [[<span style ="color:red"><font size="3">Code & Dataset</font></span>](
		 git link 
		)] [[<span style ="color:red"><font size="3">Presentation</font></span>](
			 git file link 
			)] [<a style="color:red;" href="#" onclick="$('#ecce2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] -->

<div id="ecce2023_bib" class="bib" style="display:none;"> 
	<pre>
	  @INPROCEEDINGS{,
	   author={},
	  booktitle={conference name}, 
	  title={Bengali Image Captioning Using Vision Encoder-Decoder Model}, 
	  year={2023},
	  volume={},
	  number={},
	  pages={1-6},
	  doi={}}
	</pre>
</div>

<div id="ecce2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Our research focuses on Bangla Image Captioning which involves generating descriptive captions for the images. To address this task, we propose a Vision Encoder-Decoder model, consisting of interconnected models for image encoding and text decoding. Previous work in this area has not explored the use of the Vision Encoder-Decoder Model specifically for Bangla Image Captioning. We have conducted several studies using two publicly available Bengali datasets, Bornon and BanCap, and merged them to create a comprehensive dataset to assess the performance of our model. Our proposed model outperforms recent developments in Bengali image captioning, delivering exceptional results in both quantitative and qualitative analyses.
		</font>
	</p>
</div>

<!-- Paper 02 -->
<!-- ### Under Review
--------------
⏲️ 
<span style="font-family:Trebuchet MS;color:#769FCD">**Bengali Image Captioning Using Vision Encoder-Decoder Model**</span><br>
<span style="color:black;font-family:Georgia">
	Tajrian Islam Ishan, Abdullah Al Noman, Raisa Rokib, <strong style="color:black">Mustavi Ibne Masum</strong>, Sifat Ahmed, Faisal Muhammad Shah, [ICCIT 2023](https://iccit.org.bd/2023/)
</span> -->
<!-- <span style="color:black;font-family:Georgia"><br> 
	<font size="3"><strong>Authors</strong>: Tajrian Islam Ishan, Abdullah Al Noman, Raisa Rokib, <strong style="color:black">Mustavi Ibne Masum</strong>, Sifat Ahmed, Faisal Muhammad Shah </font>
</span>
<br>
<span style="color:black;font-family:Georgia">
	<font size="3"><strong>Conference:</strong><em> The International Conference on Computer and Information Technology</em></font> ([ICCIT 2023](https://iccit.org.bd/2023/))
</span>
<br>-->
<!-- [<a style="color:red;" href="#" onclick="$('#ecce2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>]( 
	 paper link
	)] [[<span style ="color:red"><font size="3">Code & Dataset</font></span>](
		 git link 
		)] [[<span style ="color:red"><font size="3">Presentation</font></span>](
			 git file link 
			)] [<a style="color:red;" href="#" onclick="$('#ecce2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] -->

<!-- <div id="ecce2023_bib" class="bib" style="display:none;"> 
	<pre>
	  @INPROCEEDINGS{,
	   author={},
	  booktitle={conference name}, 
	  title={Bengali Image Captioning Using Vision Encoder-Decoder Model}, 
	  year={2023},
	  volume={},
	  number={},
	  pages={1-6},
	  doi={}}
	</pre>
</div>

<div id="ecce2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Our research focuses on Bangla Image Captioning which involves generating descriptive captions for the images. To address this task, we propose a Vision Encoder-Decoder model, consisting of interconnected models for image encoding and text decoding. Previous work in this area has not explored the use of the Vision Encoder-Decoder Model specifically for Bangla Image Captioning. We have conducted several studies using two publicly available Bengali datasets, Bornon and BanCap, and merged them to create a comprehensive dataset to assess the performance of our model. Our proposed model outperforms recent developments in Bengali image captioning, delivering exceptional results in both quantitative and qualitative analyses.
		</font>
	</p>
</div> -->

<!-- ⏲️  -->
<!-- <span style="font-family:Trebuchet MS;color:#769FCD">**GliomaCNN: An Effective Lightweight CNN Model in Assessment of Classifying Brain Tumor from Magnetic Resonance Images Using Explainable AI**</span><br>
<span style="color:black;font-family:Georgia">
	Md. Atiqur Rahman, <strong style="color:black">Mustavi Ibne Masum</strong>, Khan Md Hasib, M.F. Mridha, Sultan Alfarhood, Mejdl Safran, Dunren Che, [Cancers](https://www.mdpi.com/journal/cancers/) 
</span> -->

<!-- [<a style="color:red;" href="#" onclick="$('#ecce2023_abstract').toggle();return false;"><font size="3">Abstract</font></a>] [[<span style ="color:red"><font size="3">PDF</font></span>]( 
	 paper link
	)] [[<span style ="color:red"><font size="3">Code & Dataset</font></span>](
		 git link 
		)] [[<span style ="color:red"><font size="3">Presentation</font></span>](
			 git file link 
			)] [<a style="color:red;" href="#" onclick="$('#ecce2023_bib').toggle();return false;"><font size="3">Citation bib</font></a>] -->

<div id="ecce2023_bib" class="bib" style="display:none;"> 
	<pre>
	  @INPROCEEDINGS{,
	   author={},
	  booktitle={conference name}, 
	  title={GliomaCNN: An Effective Lightweight CNN Model in Assessment of Classifying Brain Tumor from Magnetic Resonance Images Using Explainable AI}, 
	  year={2023},
	  volume={},
	  number={},
	  pages={1-20},
	  doi={}}
	</pre>
</div>

<div id="ecce2023_abstract" class="abstract" style="display:none;">
	<p style="text-align:justify; color:black;font-family:Monaco;"> 
		<font size="3">
			Brain tumors pose a significant threat to human lives and have gained increasing attention as the tenth leading cause of global mortality. This study addresses the pressing issue of brain tumor classification using MRI. It focuses on distinguishing between Low-Grade Gliomas (LGG) and High-Grade Gliomas (HGG). LGGs are benign and typically manageable with surgical resection, while HGGs are malignant and more aggressive. The research introduces an innovative custom CNN model, GliomaCNN. GliomaCNN stands out as a lightweight CNN model compared to its predecessors. The research utilized the BraTS 2020 dataset for its experiments. Integrated with the gradient-boosting algorithm, GliomaCNN has achieved an impressive accuracy of 99.1569\%. The model's interpretability is ensured through SHAP and Grad-CAM++. They provide insights into critical decision-making regions for classification outcomes. Despite challenges in identifying tumors in images without visible signs, the model demonstrates remarkable performance in this critical medical application, offering a promising tool for accurate brain tumor diagnosis which paves the way for enhanced early detection and treatment of brain tumors.
		</font>
	</p>
</div>